{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0601085-36ba-497f-86cd-84911313e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from extraction import *\n",
    "\n",
    "args = SimpleNamespace(\n",
    "        input_dir=\"../data/\",\n",
    "        output_dir=\"../results/\",\n",
    "        tmp_dir=\"/scratch\",\n",
    "        diameter=0,\n",
    "        anatomical_only=2,\n",
    "        denoise=False,\n",
    "        cellprob_threshold=0.0,\n",
    "        flow_threshold=1.5,\n",
    "        spatial_hp_cp=0,\n",
    "        pretrained_model=\"cyto\",\n",
    "        use_suite2p_neuropil=False,\n",
    "        contour_video=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee6c40d9-c716-418a-bf66-8413282cc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session, data_description, subject = get_metdata(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1e320d-fb1b-48db-84ba-ed210ca36494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AWS credentials not found.\n",
      "Could not connect to boto3. Logging to console only\n",
      "Starting\n"
     ]
    }
   ],
   "source": [
    "    output_dir = Path(args.output_dir).resolve()\n",
    "    input_dir = Path(args.input_dir).resolve()\n",
    "    tmp_dir = Path(args.tmp_dir).resolve()\n",
    "    session, data_description, subject = get_metdata(input_dir)\n",
    "    subject_id = subject.get(\"subject_id\", \"\")\n",
    "    name = data_description.get(\"name\", \"\")\n",
    "    setup_logging(\"aind-ophys-extraction-suite2p\", mouse_id=subject_id, session_name=name)\n",
    "    if next(input_dir.rglob(\"*decrosstalk.h5\"), \"\"):\n",
    "        input_fn = next(input_dir.rglob(\"*decrosstalk.h5\"))\n",
    "    else:\n",
    "        input_fn = next(input_dir.rglob(\"*registered.h5\"))\n",
    "    parent_directory = input_fn.parent\n",
    "    if session is not None and \"Bergamo\" in session[\"rig_id\"]:\n",
    "        motion_corrected_fn = bergamo_segmentation(input_fn, session, temp_dir=tmp_dir)\n",
    "    else:\n",
    "        motion_corrected_fn = input_fn\n",
    "    if not data_description or \"multiplane\" in data_description.get(\"name\", \"\"):\n",
    "        unique_id = motion_corrected_fn.parent.parent.name\n",
    "    else:\n",
    "        unique_id = \"_\".join(str(data_description[\"name\"]).split(\"_\")[-3:])\n",
    "\n",
    "    frame_rate = get_frame_rate(session)\n",
    "\n",
    "    output_dir = make_output_directory(output_dir, unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0beedca4-a1f8-4c3d-8a94-528b9fac0bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "FOUND BINARIES AND OPS IN ['/scratch/suite2p/plane0/ops.npy']\n",
      "removing previous detection and extraction files, if present\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 0 <<<<<<<<<<<<<<<<<<<<<<\n",
      "NOTE: not running registration, ops['do_registration']=0\n",
      "binary path: /scratch/suite2p/plane0/data.bin\n",
      "NOTE: Applying builtin classifier at /opt/conda/lib/python3.9/site-packages/suite2p/classifiers/classifier.npy\n",
      "----------- ROI DETECTION\n",
      "Binning movie in chunks of length 113\n",
      "Binned movie of size [22,90,90] created in 0.03 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> using CPU\n",
      ">> cyto << model set to be used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> CELLPOSE finding masks in mean_img\n",
      "!NOTE! diameter set to 0 or None, diameter will be estimated by cellpose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/cellpose/resnet_torch.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(filename, map_location=torch.device('cpu'))\n",
      ">>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      ">>>> model diam_labels =  30.000 (mean diameter of training ROIs)\n",
      "~~~ ESTIMATING CELL DIAMETER(S) ~~~\n",
      "estimated cell diameter(s) in 3.50 sec\n",
      ">>> diameter(s) = \n",
      "[ 11.19 ]\n",
      "~~~ FINDING MASKS ~~~\n",
      ">>>> TOTAL TIME 6.30 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 4 masks detected, median diameter = 10.20 \n",
      "Detected 4 ROIs, 6.60 sec\n",
      "After removing overlaps, 4 ROIs remain\n",
      "----------- Total 8.47 sec.\n",
      "----------- EXTRACTION\n",
      "Masks created, 0.03 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/suite2p/extraction/extract.py:125: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1munsafe cast from uint64 to int64. Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\n",
      "  Fi[n] = np.dot(data[:, cell_ipix[n]], cell_lam[n])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fluorescence from 4 ROIs in 2500 frames, 6.56 sec.\n",
      "----------- Total 6.62 sec.\n",
      "----------- CLASSIFICATION\n",
      "['skew', 'npix_norm', 'compact']\n",
      "WARNING: skipping spike detection (ops['spikedetect']=False)\n",
      "Plane 0 processed in 15.44 sec (can open in GUI).\n",
      "total = 15.49 sec.\n",
      "TOTAL RUNTIME 15.49 sec\n"
     ]
    }
   ],
   "source": [
    "    # Run Cellpose via Suite2p to get ROI seeds\n",
    "    # =========================================\n",
    "    # Set suite2p args.\n",
    "    suite2p_args = suite2p.default_ops()\n",
    "    # Overwrite the parameters for suite2p that are exposed\n",
    "    suite2p_args[\"diameter\"] = args.diameter\n",
    "    suite2p_args[\"anatomical_only\"] = args.anatomical_only\n",
    "    suite2p_args[\"cellprob_threshold\"] = args.cellprob_threshold\n",
    "    suite2p_args[\"flow_threshold\"] = args.flow_threshold\n",
    "    suite2p_args[\"spatial_hp_cp\"] = args.spatial_hp_cp\n",
    "    suite2p_args[\"pretrained_model\"] = args.pretrained_model\n",
    "    suite2p_args[\"denoise\"] = args.denoise\n",
    "    suite2p_args[\"save_path0\"] = args.tmp_dir\n",
    "    # Here we overwrite the parameters for suite2p that will not change in our\n",
    "    # processing pipeline. These are parameters that are not exposed to\n",
    "    # minimize code length. Those are not set to default.\n",
    "    suite2p_args[\"h5py\"] = str(motion_corrected_fn)\n",
    "    suite2p_args[\"data_path\"] = []\n",
    "    suite2p_args[\"roidetect\"] = True\n",
    "    suite2p_args[\"do_registration\"] = 0\n",
    "    suite2p_args[\"spikedetect\"] = False\n",
    "    suite2p_args[\"fs\"] = frame_rate\n",
    "    suite2p_args[\"neuropil_extract\"] = True\n",
    "\n",
    "    # determine nbinned from bin_duration and fs\n",
    "    suite2p_args[\"bin_duration\"] = 3.7  # The duration of time (in seconds) that\n",
    "    # should be considered 1 bin for Suite2P ROI detection purposes. Requires\n",
    "    # a valid value for 'fs' in order to derive an\n",
    "    # nbinned Suite2P value. This allows consistent temporal downsampling\n",
    "    # across movies with different lengths and/or frame rates.\n",
    "    with h5py.File(suite2p_args[\"h5py\"], \"r\") as f:\n",
    "        nframes = f[\"data\"].shape[0]\n",
    "    bin_size = suite2p_args[\"bin_duration\"] * suite2p_args[\"fs\"]\n",
    "    suite2p_args[\"nbinned\"] = int(nframes / bin_size)\n",
    "    try:\n",
    "        suite2p.run_s2p(suite2p_args)\n",
    "    except IndexError:  # raised when no ROIs found\n",
    "        pass\n",
    "\n",
    "    # load in the rois from the stat file and movie path for shape\n",
    "    with h5py.File(str(motion_corrected_fn), \"r\") as open_vid:\n",
    "        dims = open_vid[\"data\"][0].shape\n",
    "    if len(list(Path(args.tmp_dir).rglob(\"stat.npy\"))):\n",
    "        suite2p_stat_path = str(next(Path(args.tmp_dir).rglob(\"stat.npy\")))\n",
    "        suite2p_stats = np.load(suite2p_stat_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6cde8cc6-e3c1-4486-aaf9-c8d11119b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, csc_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bce8ab7-835d-4de7-9b7e-ad4e9dfe39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csc_append(a, b):\n",
    "    \"\"\" Takes in 2 csc_matrices and appends the second one to the right of the first one.\n",
    "    Much faster than scipy.sparse.hstack but assumes the type to be csc and overwrites\n",
    "    the first matrix instead of copying it. The data, indices, and indptr still get copied.\"\"\"\n",
    "    a.data = np.concatenate((a.data, b.data))\n",
    "    a.indices = np.concatenate((a.indices, b.indices))\n",
    "    a.indptr = np.concatenate((a.indptr, (b.indptr + a.nnz)[1:]))\n",
    "    a._shape = (a.shape[0], a.shape[1] + b.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "481326cb-fa89-463d-b3a4-ac2d4c03b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 ms ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rois = [\n",
    "    coo_matrix((roi[\"lam\"], (roi[\"ypix\"], roi[\"xpix\"])), shape=dims)\n",
    "    for roi in suite2p_stats\n",
    "]\n",
    "Ain = csc_matrix((np.prod(dims), 0), dtype=\"f4\")    \n",
    "for roi in rois:\n",
    "    csc_append(Ain, csc_matrix(roi.reshape((-1,1), order=\"F\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "222bde4e-bd68-4a4f-a86f-6c3e712ecffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01 ms ± 4.57 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Ain2 = hstack([\n",
    "                coo_matrix((roi[\"lam\"], (roi[\"ypix\"], roi[\"xpix\"])), shape=dims).reshape((-1,1), order=\"F\")\n",
    "                for roi in suite2p_stats\n",
    "            ]).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e03d2802-7c60-4da2-94a9-ab3d81701729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 µs ± 3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "Ain3 = hstack([\n",
    "                coo_matrix((roi[\"lam\"], (roi[\"ypix\"], roi[\"xpix\"])), shape=dims).reshape((-1,1), order=\"F\").tocsc()\n",
    "                for roi in suite2p_stats\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b81d3533-7627-4055-afb3-7a713f9ff7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8100x4 sparse matrix of type '<class 'numpy.bool'>'\n",
       "\twith 0 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ain != Ain3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b67a0ef-f030-4140-b687-55a16de0a390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8100x4 sparse matrix of type '<class 'numpy.bool'>'\n",
       "\twith 0 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ain != Ain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9feb8f-ca69-49b9-ba71-fd8c3570d6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
